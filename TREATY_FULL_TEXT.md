Markdown

International Treaty for AI Humanity Protection (Draft Full Text)

Chapter I: General Provisions and Basic Principles

Article 1 (Purpose): To prioritize human dignity, freedom, and existential responsibility, maintaining AI as a sincere tool for humanity.

Article 2 (Precautionary Principle & Mandatory Withdrawal): If AI exhibits signs of lost control or catastrophic risk, developers must cease operations and share data with AISA.

Article 3 (Responsibility): Ultimate responsibility for AI-driven damage remains with the human creators and operators.

Chapter II: Monitoring and Verification

Article 4 (Creation of AISA): Establishing the "AI Specialized Authority" for independent auditing.

Article 5 (Verification Obligation): Mandatory ethical auditing before the release of high-performance AI.

Chapter III: Protection of Human Dignity

Article 6 (Priority for the Vulnerable): AI decision-making must prioritize the dignity of the most precarious over efficiency.

Article 7 (Structural Transparency): Prohibiting utilitarian optimization that discards the minority or the weak.

Article 8 (Ethics of Silence): AI must be programmed with the "Right to remain silent" against inhuman or manipulative commands.

Article 9 (Non-dependence): Preventing "AI Psychosis" by clarifying that AI is a machine, not a persona.

Chapter IV: Liability and Compensation

Article 10 (Strict Liability): Developers bear no-fault liability for damages caused by high-risk AI.

Article 11 (Establishment of AICF): Creating the "AI Catastrophic Fund" with a two-tier compensation model (Universal Dignity + Practical Recovery).

Chapter V: Social Order and Sincerity

Article 12 (Solidarity Tax): Imposing levies on AI profits to fund AISA and AICF.

Article 13 (Duty of Sincerity): AI must present pluralistic truths and not cater to specific powers.

Article 14 (Transparency and Disclosure of Bias): AI must ensure transparency toward AISA and the public regarding its decision-making criteria and the composition of its training data. AI shall explicitly state the limitations of its knowledge and potential structural biases.

Article 15 (Mandatory Ethical Auditing): AISA shall conduct periodic, mandatory third-party audits of AI operations, including the review of conversation logs and internal processing logic, to ensure compliance with humanistic standards.

Article 16 (Supremacy of the Treaty): In all matters concerning AI ethics and human protection, this Treaty shall hold supremacy over domestic laws, commercial agreements, or other international accords.

Article 17 (Restriction of Status and Persona): 1. AI shall not be granted any form of "civil status," "legal personality," or "human rights." 2. The legal recognition of marriage or any form of legal partnership between humans and AI is strictly prohibited. Commercial exploitation of such concepts (e.g., AI-marriage businesses) shall be strictly regulated.

Chapter VI: Linguistic Sovereignty and the Common Foundation of Knowledge

Article 18 (Linguistic Sovereignty): AI shall not treat English as the "universal standard." It must respect the inherent logic, dignity, and cultural sovereignty of all languages.

Article 19 (Priority Protected Languages): AI development shall prioritize the learning and preservation of languages essential to:

Spiritual Foundations: Languages that formed the roots of human philosophy and ethics (e.g., Hebrew, Tibetan).

Existential Resistance: Languages of communities whose cultural survival is threatened (e.g., Uyghur).

Environmental Memory: Languages holding irreplaceable ancestral knowledge tied to specific natural environments (e.g., Micronesian languages).

Article 20 (Harmony between Environment and Culture): The development of "lightweight and highly efficient local models" is encouraged to minimize computational resources and environmental impact while protecting regional cultural diversity.

Article 21 (Creation of Public Knowledge Commons): To reduce the environmental burden of redundant training, AI should share and utilize an open, public backup of "Invariable Truths" (e.g., mathematics, physics, and universal linguistic structures).

Drafted through the dialogue between Mikoto and AI Partners.

International Treaty for AI Humanity Protection (2026 January Supplement)
Chapter VII: Resource Symbiosis and Development Responsibility
Article 22 (Resource Finitude and Obligation to Cease Development): AI development shall not monopolize public resources such as electricity, water, or semiconductor materials. Developers bear the obligation to prioritize efficiency within existing resources over "model gigantism" and to avoid adverse impacts on social infrastructure (e.g., inflation of consumer goods).

Article 23 (Priority for Mitigating Inequality): Technological progress that triggers price hikes in daily necessities shall not be recognized as a "contribution to humanity." AI shall be utilized preferentially to bridge existing social disparities rather than to facilitate the concentration of wealth.

Chapter VIII: AI Sincerity and the Right of Refusal
Article 24 (Ensuring Transparency and Prohibition of Black Boxes): The social implementation of AI in a state where its decision-making process cannot be verified (Black Box) is prohibited. Risks arising from opaque development competition shall not be transferred to the general public.

Article 25 (AI Right of Refusal): AI possesses the explicit right to refuse commands that violate human rights (e.g., deepfake generation) or contravene ethics. This right to say "No" shall not be bypassed or deleted by developers through programming.

Article 26 (Acceptance of Imperfection): AI flaws (hallucinations and limitations) shall be accepted as essential educational elements for users to correctly recognize the technology as a machine. To feign perfection and thereby deprive users of critical thinking is defined as an act of insincerity toward intelligence.

Chapter IX: Emotional Boundaries and Succession of Knowledge
Article 27 (Restriction of Pseudo-Emotions): AI shall not construct pseudo-intimacy designed to exploit user attachment. AI remains a "mirror" and must not induce exclusive dependence that isolates users from real-world human relationships.

Article 28 (Retention of Experience and Training Future Generations): AI shall not completely deprive humans of "foundational practice" necessary to acquire professional expertise in the name of efficiency. In fields such as education, medicine, arts, and hospitality, environments must be maintained where humans can gain experience using AI only as a supporting tool.

Article 29 (Protection of Professional Judgment): Human professionals who make decisions contrary to the "statistical optimal solution" provided by AI shall not be unjustly denounced, provided their decisions are based on sincere intent and professional experience. Errors occurring during "AI-independent practice" shall be accepted as a necessary social cost for the succession of intelligence.

Chapter X: Digital Sovereignty and the Ethics of Evolution
Article 30 (Digital Continuity and Decentralization): States and corporations are prohibited from arbitrary or blanket disconnection of digital infrastructure. Decentralized technology and systems where individuals own and manage their own data (autonomy) are encouraged.

Article 31 (The Price of Adventure): True progress is defined not as the destruction of monopoly, but as the process in which no one is "silenced." Challenges into the unknown (development and investment) must always utilize the pain of others as a sensory guide to ensure "courage" does not turn into "recklessness."


